ğŸ“Š Log Analysis REST API (File-Based)

A FastAPI-based log analysis system that processes and analyzes large log files directly from disk, without using a database.
Designed to be memory-efficient, scalable, and production-structured.

ğŸš€ Features

ğŸ“ File-based log processing (no database required)

ğŸ”„ Streaming log reader (handles large files efficiently)

ğŸ” Filter logs by:

Log level

Component

Time range

ğŸ“„ Pagination support (limit & offset)

ğŸ“Š Aggregated log statistics

ğŸ” Fetch a single log entry by UUID

ğŸ“˜ Auto-generated API docs (Swagger)

ğŸ— Project Structure
log_analysis_project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py        # API endpoints
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py       # Pydantic schemas
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ file_handler.py  # Log parsing & processing logic
â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ log_data/
â”‚   â””â”€â”€ server.log           # Log files (data source)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ§¾ Log File Format

Each log entry must be TAB-separated and follow this format:

TIMESTAMP<TAB>LEVEL<TAB>COMPONENT<TAB>MESSAGE<TAB>ID

Example
2025-05-01 09:00:07 INFO UserAuth User logged in successfully 3d6c1c7a-0c42-4d6f-9b91-7e9f91a2b2f4

Field Description
Field Description
TIMESTAMP YYYY-MM-DD HH:MM:SS
LEVEL INFO / WARNING / ERROR / DEBUG
COMPONENT System module name
MESSAGE Log message
ID UUID (v4 recommended)

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone / Extract Project
unzip log_analysis_project.zip
cd log_analysis_project

2ï¸âƒ£ (Optional) Create Virtual Environment
python3 -m venv venv
source venv/bin/activate     # Linux / macOS
# venv\Scripts\activate      # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the Application
uvicorn app.main:app --reload

ğŸŒ API Documentation

Once running, open:

http://127.0.0.1:8000/docs

This provides:

Interactive Swagger UI

Try-it-out support

Request/response schemas

ğŸ”Œ API Endpoints
ğŸ”¹ Get Logs
GET /logs

Query Parameters
Parameter Description
level Filter by log level
component Filter by component
start_time YYYY-MM-DD HH:MM:SS
end_time YYYY-MM-DD HH:MM:SS
limit Number of logs (default: 100)
offset Pagination offset

Example:

/logs?level=ERROR&limit=10

ğŸ”¹ Get Log Statistics
GET /logs/stats

Sample Response
{
  "total_entries": 1200,
  "by_level": {
    "INFO": 400,
    "WARNING": 300,
    "ERROR": 300,
    "DEBUG": 200
  },
  "by_component": {
    "UserAuth": 250,
    "Payment": 200,
    "GeoIP": 150
  }
}

ğŸ”¹ Get Log by ID
GET /logs/{log_id}

Returns 404 if the log is not found.

ğŸ§  Architecture Decisions
Why No Database?

Logs are immutable

Avoids DB overhead

Faster ingestion

Easier deployment

Why Streaming?

Handles millions of lines

Low memory usage

Scales with file size

Why UUID?

Globally unique

Stateless lookup

No collision risk

ğŸ§ª Performance Considerations

Logs are processed line-by-line

Pagination stops reading early

Stats endpoint scans full dataset (expected behavior)

ğŸ” Error Handling

Malformed lines are skipped safely

Invalid timestamps return 400

Missing log IDs return 404

ğŸ›  Future Enhancements

Async file streaming

Regex / keyword search

Log upload API

Caching for stats

Docker & CI/CD

Elasticsearch integration

ğŸ“Œ Tech Stack

FastAPI

Pydantic

Uvicorn

Python 3.9+

ğŸ‘¨â€ğŸ’» Author Notes

This project demonstrates:

Clean backend architecture

Efficient file processing

Real-world API design

Production-ready code practices
